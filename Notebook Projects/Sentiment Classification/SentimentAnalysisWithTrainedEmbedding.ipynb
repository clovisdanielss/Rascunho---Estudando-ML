{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257cab10-e78d-4929-83b9-7eea5f153853",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "Esse objetivo tem como objetivo utilizar um modelo multi-linguagens do tensorflow hub como embedding. Simplesmente, a ideia central é realizar a aplicação de uma rede bem simples com esse embedding. \n",
    "\n",
    "Em teoria espera-se uma performance melhor do que a encontrada anteriormente.\n",
    "\n",
    "Nos experimentos anterioriores, para as 5 classes a RNN conseguiu 33% de precisão na validação para as 5 classes. O que é horrível, considerando que um experimento aleatório teria 20% de precisão na validação. A LSTM teve uma performance pior ainda que foi justamente de 20% de precisão na validação, o que implica que não foi possível generalizar.\n",
    "\n",
    "Aqui, veremos se com um embedding existente é possível generalizar melhor esses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29afbd2b-052d-4f56-9db4-21c7df7a163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d94d2d3-c71b-4336-85bc-cd7b79f4fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "embed_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\", input_shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea17333e-6e71-46b6-b8a3-d6a4eb3eedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_samples(reader, data, samples_max_size, data_size):\n",
    "    for _ in reader:\n",
    "        validate = data[\"overall\"].value_counts().sum()\n",
    "        if validate == data_size:\n",
    "            break\n",
    "        for i in range(1,6):\n",
    "            aux = _.groupby(\"overall\").filter(lambda x: pd.Series([i]).isin(x[\"overall\"]).all())[data.columns]\n",
    "            curr_class_size = data[\"overall\"].value_counts()[i]\n",
    "            if curr_class_size + aux.shape[0] < samples_max_size:\n",
    "                #adiciona\n",
    "                data = pd.concat([data, aux], axis = 0)\n",
    "            elif curr_class_size < samples_max_size:\n",
    "                #adiciona parcial\n",
    "                offset = curr_class_size + aux.shape[0] - samples_max_size\n",
    "                data = pd.concat([data, aux[offset:]], axis = 0)\n",
    "            else:\n",
    "                clear_output(wait=True)\n",
    "                print(data[\"overall\"].value_counts())\n",
    "                continue\n",
    "            clear_output(wait=True)\n",
    "            print(data[\"overall\"].value_counts())\n",
    "    return data\n",
    "\n",
    "def initialize_data(chunksize, proportion_train, exclude_classes = [], padding=40):\n",
    "    data_size = 5*chunksize\n",
    "\n",
    "    reader = pd.read_json(\"./dataset/Video_Games.json\", chunksize=chunksize, lines=True)\n",
    "\n",
    "    data = []\n",
    "    for _ in reader:\n",
    "        data.append(_)\n",
    "        break\n",
    "    data = data[0]\n",
    "\n",
    "    samples_max_size = chunksize\n",
    "\n",
    "    data = equalize_samples(reader,data,samples_max_size,data_size)\n",
    "\n",
    "    for i in exclude_classes:\n",
    "        data = data[data.overall != i]\n",
    "    \n",
    "    data.dropna(subset=[\"reviewText\"],  axis=0, inplace=True)\n",
    "    clear_output(wait=True)\n",
    "    print(data[\"overall\"].value_counts())\n",
    "    #data[\"reviewText\"] = data[\"reviewText\"].apply(lambda x: (nltk.wordpunct_tokenize(x) + [\"<PAD>\"] * padding)[:padding])\n",
    "    x = data[\"reviewText\"].to_numpy()\n",
    "    print(x[:5])\n",
    "    y = pd.get_dummies(data[\"overall\"].to_numpy()).to_numpy()\n",
    "    print(y[:5])\n",
    "    return sklearn.model_selection.train_test_split(x, y, train_size=proportion_train) + [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970b2651-246f-41f2-83a7-526ca9765d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    5000\n",
      "1    4995\n",
      "Name: overall, dtype: int64\n",
      "['I used to play this game years ago and loved it. I found this did not work on my computer even though it said it would work with Windows 7.'\n",
      " 'The product description should state this clearly. The CD, the box, and the product description suggest that the game is compatible with all Macs. It is not.'\n",
      " 'Choose your career which sets your money for the trip.  Then name how many and who will be traveling with you.  Before you leave town, you must go into town  choose wagons or Conestoga, animals and many supplies -watch your cash and your wagon weight!  On your journey you can talk with different people to make decisions about your next moves.  You also get to hunt, fish, & gather..Be careful of disease & rivers!'\n",
      " 'It took a few hours to get this up and running on Windows 8 computer and Windows XP.  If you get an error go and download their patch.\\n\\n[...]\\n\\nJust the patch alone worked like a charm on Windows XP.  For Windows 8 I download the patch AND had to change the compatibility to WIndows ME.\\n\\nClassic game that the kids learn so much from...worth it.'\n",
      " 'I oredered this for a daughter who is now 33 and she wanted to play the Oregon Trail that we had years ago...she and her fmily have had a blast with it..we laughed a lot as she would holler and squeal as she played the game.........so it has met all our expectations..']\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "samples_size=5000\n",
    "xtrain, xtest, ytrain, ytest, data = initialize_data(samples_size,.9, exclude_classes=[2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0b362b-1a87-4a92-86f7-89984a491b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmax(tf.keras.layers.Softmax):\n",
    "    def __init__(self):\n",
    "        super(LogSoftmax, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.math.log(super(LogSoftmax, self).call(inputs))\n",
    "        \n",
    "    \n",
    "def my_model(output=2, embedding_dim=128, epochs=50, patience=3):\n",
    "    \n",
    "    symbolic_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "    embedding = embed_layer(symbolic_input)\n",
    "    #dense_n = tf.keras.layers.Dense(128)(embedding)\n",
    "    dense_n = tf.keras.layers.Dense(64)(embedding)\n",
    "    dense_n = tf.keras.layers.Dense(32)(dense_n)\n",
    "    dense_1 = tf.keras.layers.Dense(output)(dense_n)\n",
    "    pred = LogSoftmax()(dense_1)\n",
    "    rnn = tf.keras.models.Model(inputs=[symbolic_input], outputs=pred)\n",
    "    print(rnn.summary())\n",
    "\n",
    "    rnn.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = rnn.fit(\n",
    "        x = xtrain,\n",
    "        y = ytrain, \n",
    "        epochs=epochs, \n",
    "        batch_size=64,\n",
    "        validation_data=(xtest,ytest),\n",
    "        verbose=True,\n",
    "        callbacks=EarlyStopping(monitor='val_accuracy', mode='max',patience=patience)\n",
    "    ),\n",
    "\n",
    "    history = history[0]\n",
    "    for i in range(1,6):\n",
    "        print(\"Epoca:{0}, Acurácia:{1}, Acurácia_Val:{2}, Perca:{3}\".format(epochs-i+1,history.history[\"accuracy\"][-i],history.history[\"val_accuracy\"][-i], history.history[\"loss\"][-i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7079d7cc-e216-4074-b872-a61c34e7ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (None, 512)               68927232  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "log_softmax (LogSoftmax)     (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 68,962,210\n",
      "Trainable params: 34,978\n",
      "Non-trainable params: 68,927,232\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 66s 409ms/step - loss: 0.3019 - accuracy: 0.8825 - val_loss: 0.2275 - val_accuracy: 0.9110\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 58s 411ms/step - loss: 0.2069 - accuracy: 0.9194 - val_loss: 0.2253 - val_accuracy: 0.9110\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.2007 - accuracy: 0.9201 - val_loss: 0.2235 - val_accuracy: 0.9100\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 55s 387ms/step - loss: 0.1976 - accuracy: 0.9237 - val_loss: 0.2287 - val_accuracy: 0.9140\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 55s 388ms/step - loss: 0.1931 - accuracy: 0.9237 - val_loss: 0.2280 - val_accuracy: 0.9150\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 55s 392ms/step - loss: 0.1920 - accuracy: 0.9243 - val_loss: 0.2264 - val_accuracy: 0.9120\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 55s 391ms/step - loss: 0.1891 - accuracy: 0.9266 - val_loss: 0.2268 - val_accuracy: 0.9090\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 58s 411ms/step - loss: 0.1874 - accuracy: 0.9260 - val_loss: 0.2284 - val_accuracy: 0.9110\n",
      "Epoca:50, Acurácia:0.9259588718414307, Acurácia_Val:0.9110000133514404, Perca:0.18742398917675018\n",
      "Epoca:49, Acurácia:0.9266259074211121, Acurácia_Val:0.9089999794960022, Perca:0.1890655755996704\n",
      "Epoca:48, Acurácia:0.9242912530899048, Acurácia_Val:0.9120000004768372, Perca:0.19197426736354828\n",
      "Epoca:47, Acurácia:0.9237353801727295, Acurácia_Val:0.9150000214576721, Perca:0.1930752843618393\n",
      "Epoca:46, Acurácia:0.9237353801727295, Acurácia_Val:0.9139999747276306, Perca:0.19755513966083527\n"
     ]
    }
   ],
   "source": [
    "my_model(output=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0659525-e92f-4016-9f7a-7116fa18a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    3000\n",
      "5    3000\n",
      "2    3000\n",
      "3    2999\n",
      "1    2996\n",
      "Name: overall, dtype: int64\n",
      "['I used to play this game years ago and loved it. I found this did not work on my computer even though it said it would work with Windows 7.'\n",
      " 'The game itself worked great but the story line videos would never play, the sound was fine but the picture would freeze and go black every time.'\n",
      " \"I had to learn the hard way after ordering this for my MacBook Pro that this doesn't work unless you have MAC OS version 10.3 or less. I found that out after contact the Learning Company directly. They were very prompt in their response. However, I also have a laptop with Microsoft 7. This program loaded beautifully with the Microsoft base. So, if you have Microsoft 7 or 8, purchase and enjoy this game. Any mac systems will likely have issues.\"\n",
      " 'The product description should state this clearly. The CD, the box, and the product description suggest that the game is compatible with all Macs. It is not.'\n",
      " 'I would recommend this learning game for anyone who likes learning about history\\nI really like playing this history game']\n",
      "[[1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (None, 512)               68927232  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "_________________________________________________________________\n",
      "log_softmax_1 (LogSoftmax)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 68,962,309\n",
      "Trainable params: 35,077\n",
      "Non-trainable params: 68,927,232\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "211/211 [==============================] - 130s 607ms/step - loss: 1.2875 - accuracy: 0.4517 - val_loss: 1.2007 - val_accuracy: 0.4853\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - 131s 623ms/step - loss: 1.1477 - accuracy: 0.5137 - val_loss: 1.1818 - val_accuracy: 0.4933\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - 128s 605ms/step - loss: 1.1248 - accuracy: 0.5269 - val_loss: 1.1647 - val_accuracy: 0.5007\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - 127s 603ms/step - loss: 1.1117 - accuracy: 0.5381 - val_loss: 1.1654 - val_accuracy: 0.5147\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - 131s 624ms/step - loss: 1.1043 - accuracy: 0.5378 - val_loss: 1.1648 - val_accuracy: 0.5047\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - 126s 596ms/step - loss: 1.0992 - accuracy: 0.5423 - val_loss: 1.1613 - val_accuracy: 0.5047\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - 126s 599ms/step - loss: 1.0931 - accuracy: 0.5415 - val_loss: 1.1657 - val_accuracy: 0.5020\n",
      "Epoca:50, Acurácia:0.541533887386322, Acurácia_Val:0.5019999742507935, Perca:1.0930733680725098\n",
      "Epoca:49, Acurácia:0.5422748923301697, Acurácia_Val:0.5046666860580444, Perca:1.0992485284805298\n",
      "Epoca:48, Acurácia:0.537828803062439, Acurácia_Val:0.5046666860580444, Perca:1.1043388843536377\n",
      "Epoca:47, Acurácia:0.538125216960907, Acurácia_Val:0.5146666765213013, Perca:1.111670970916748\n",
      "Epoca:46, Acurácia:0.5268617868423462, Acurácia_Val:0.5006666779518127, Perca:1.1248093843460083\n"
     ]
    }
   ],
   "source": [
    "samples_size=3000\n",
    "xtrain, xtest, ytrain, ytest, data = initialize_data(samples_size,.9, exclude_classes=[])\n",
    "my_model(output=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40f34d-38d3-4781-bcc6-abd2bf523081",
   "metadata": {},
   "source": [
    "#### Usando um Embedding treinado\n",
    "\n",
    "Não foi preciso nem aplicar LSTM ou RNN. O modelo atingiu uma performance muito maior. 93% de precisão para o problema binário e 54% de precisão para o problema com 5 classes.\n",
    "\n",
    "Deu OOM acima porque tive que abrir uma porrada de coisa porque também estava fazendo outra coisa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9beab3-a7f1-42cd-8c6a-5e4fff79d353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
