{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento de modelos.\n",
    "\n",
    "Com spacy é possível se treinar os próprios modelos (O que é obvio visto que é uma lib de NLP).\n",
    "Neste caso, o treinamento pode ser apresentado da seguinte forma.\n",
    "1. <strong>Inicializa</strong> os pesos de forma aleatória com <code>nlp.begin_training</code>.\n",
    "2. <strong>Prevê</strong> alguns exemplos utilizando os pesos atuais com o <code>nlp.update</code>.\n",
    "3. <strong>Calcula</strong> como alterar os pesos para melhorar as previsões.\n",
    "4. <strong>Atualiaza</strong> ligeiramente os pesos do modelo.\n",
    "5. Volta ao passo 2.\n",
    "\n",
    "A imagem a seguir ilustra esse processo\n",
    "![processo](https://course.spacy.io/training.png)\n",
    "\n",
    "Importante salientar que:\n",
    "1. <strong>Training Data:</strong> se refere aos dados de treinamento.\n",
    "2. <strong>Text:</strong> se refere ao texto de entrada que a previsão deve ser feita.\n",
    "3. <strong>Label:</strong> rótulo ou marcador, resultado da previsão do modelo.\n",
    "4. <strong>Gradient:</strong> método usado para alterar os pesos e reduzir o erro.\n",
    "\n",
    "\n",
    "Outro fator muito importante é que o spacy3.0, faz uso de um loop de treinamento diferente das versões anteriores.\n",
    "Primeiro devemos levar em conta a classe <code>spacy.training.Example</code>. \n",
    "A função <code>nlp.update</code>, vai esperar justamente uma lista de Exemplos para treinar o modelo.\n",
    "\n",
    "E uma pergunta que tava me vendo a mente quando lia a documentação foi: Vou ter que transformar em doc a string de treino ? Isso não vai obrigar a passar por todo pipeline ? - Engano meu, existe a função <code>nlp.make_doc</code> que eu tinha visto em um tutorial mas tinha esquecido da existência.\n",
    "\n",
    "Assim, podemos criar um exemplo da seguinte forma:\n",
    "<code>Example.from_dic(nlp.make_doc(text), annotation)</code>\n",
    "\n",
    "Considere que <code>text</code> é uma string, e <code>annotation</code> é um dicionário contendo as anotações referente aquele doc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['textcat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"pt\")\n",
    "\n",
    "### Pouco treino...\n",
    "training = [\n",
    "    ('Isso é um teste para saber se a parada tá funcionando', {\"cats\":{'TESTE': True, 'MSG': False}}),\n",
    "    ('Oi, tudo bem com você ?', {\"cats\":{'TESTE': False, 'MSG': True}}),\n",
    "    ('Testando 1,2,3...', {\"cats\":{'TESTE': True, 'MSG': False}}),\n",
    "    ('Teste teste', {\"cats\":{'TESTE': True, 'MSG': False}}),\n",
    "    ('Mais uma frase aleatória',{\"cats\":{'TESTE': False, 'MSG': True}})\n",
    "]\n",
    "\n",
    "\n",
    "textcat = nlp.add_pipe(\"textcat\")\n",
    "textcat.add_label(\"TESTE\")\n",
    "textcat.add_label(\"MSG\")\n",
    "\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "from spacy.util import minibatch\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "def train(model, train_data, optimizer):\n",
    "    losses = {}\n",
    "    for epoch in range(30):\n",
    "        random.shuffle(train_data)\n",
    "\n",
    "        batches = minibatch(train_data, size=2)\n",
    "        for batch in batches:\n",
    "            # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n",
    "            # Split batch into texts and labels\n",
    "            texts = [text for text, annotation in batch]\n",
    "            annotations = [annotation for text, annotation in batch]\n",
    "            examples = []\n",
    "            for text, annots in batch:\n",
    "                examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "                nlp.initialize(lambda: examples)\n",
    "            # Update model with texts and labels\n",
    "            model.update(examples, sgd=optimizer)\n",
    "        \n",
    "    return losses\n",
    "\n",
    "train(nlp, training, nlp.begin_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 0], dtype=int64), ('TESTE', 'MSG'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Modelo horrivel rsrsrsrs\n",
    "docs = list(nlp.pipe([\n",
    "   \"Isto foi um teste\",\n",
    "    \"Meu nome é Clóvis\",\n",
    "    \"Gosto de biscoito\",\n",
    "    \"Não gosto de testar\",\n",
    "    \"Mais outro teste\"\n",
    "]))\n",
    "scores = nlp.get_pipe('textcat').predict(docs)\n",
    "scores.argmax(axis=1),nlp.get_pipe('textcat').labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(nlp, training, nlp.begin_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
