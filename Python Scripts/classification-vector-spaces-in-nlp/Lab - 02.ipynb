{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisão de probabilidade\n",
    "\n",
    "Primeiramente, sabemos que:\n",
    "$$P(X) = \\frac{total_{x}}{total_{eventos}}$$\n",
    "\n",
    "Isto é, a probabilidade de um evento X ocorrer, é igual ao total de vezes que ele ocorre em uma amostragem sob o total da amostragem.\n",
    "\n",
    "Também sabemos a probabilidade que a probabilidade de dois eventos ocorrerem simultaneamente é dado por:\n",
    "\n",
    "$$P(A,B) = P(A\\cap B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "Por último é sabido que a probabilidade de A dado B é:\n",
    "\n",
    "$$P(A | B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Com isso, sem perda de generalidade, deduzimos que:\n",
    "\n",
    "$$P(A | B) = \\frac{P(B | A) * P(A)}{P(B)}$$\n",
    "\n",
    "A essa equação que definimos como regra de Bayes.\n",
    "\n",
    "### Laboratório 2\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "Faz uso da regra de Bayes para computar a probabilidade de um evento. É chamada de \"naive\" porque presupõe que as variáveis são independentes.\n",
    "\n",
    "A regra de Bayes nesse método é aplicado da seguinte forma\n",
    "\n",
    "$$\\prod_{i=1}^{m}{\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)}}$$\n",
    "\n",
    "#### Desvatagens do método\n",
    "\n",
    "    1. Assume que as palavras são indepentes umas das outras. Mas sabemos que o contexto influencia no texto.\n",
    "    2. Depende da frequência do corpo do texto. Características importantes podem passar, caso haja falta de frequência no texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mesmo início de código da outra aula\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "corpo = [\n",
    "    \"Eu gosto de comer biscoito\",\n",
    "    \"Eu odeio você\",\n",
    "    \"Eu te amo!!\",\n",
    "    \"Você é o amor da minha vida\",\n",
    "    \"Vá para a baixa da égua\",\n",
    "    \"Você é uma pessoa repugnante\",\n",
    "    \"Você é desagradável\",\n",
    "    \"Você é amável\"\n",
    "]\n",
    "\n",
    "classes = [\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1\n",
    "]\n",
    "\n",
    "dados = pd.DataFrame({\"corpo\":corpo, \"classes\":classes})\n",
    "vocabulario = {}\n",
    "indices = {}\n",
    "pontuacao = ['!',\",\"]\n",
    "palavrasPausa = [\"a\", \"é\", \"uma\", \"de\", \"o\", \"da\"]\n",
    "def criarVocabulario(corpo):\n",
    "    v = {}\n",
    "    i = {}\n",
    "    index = 0\n",
    "    for frase in corpo:\n",
    "        for palavra in frase.split(\" \"):\n",
    "            for p in pontuacao:\n",
    "                palavra = palavra.replace(p,'')\n",
    "            if palavra not in list(v.keys()) and palavra not in palavrasPausa:\n",
    "                v[palavra] = index\n",
    "                i[index] = palavra\n",
    "                index+=1\n",
    "    return v,i    \n",
    "\n",
    "vocabulario, indices = criarVocabulario(corpo)\n",
    "\n",
    "def medirFrequencia(frase):\n",
    "    array = np.zeros(len(list(vocabulario.keys())))\n",
    "    for palavra in frase.split(\" \"):\n",
    "        for p in pontuacao:\n",
    "            palavra = palavra.replace(p,'')\n",
    "        if palavra not in palavrasPausa:\n",
    "            array[vocabulario[palavra]] += 1\n",
    "    return array\n",
    "def somarFrequencia(data):\n",
    "    arrayPositivo = np.zeros(len(list(vocabulario.keys())))\n",
    "    arrayNegativo = np.zeros(len(list(vocabulario.keys())))\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data.iloc[i,1] == 1:\n",
    "            arrayPositivo += medirFrequencia(data.iloc[i,0])\n",
    "        else:\n",
    "            arrayNegativo += medirFrequencia(data.iloc[i,0])\n",
    "    return arrayPositivo, arrayNegativo\n",
    "\n",
    "positivos, negativos = somarFrequencia(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.15384615, 0.07692308, 0.07692308, 0.07692308, 0.        ,\n",
       "        0.        , 0.07692308, 0.07692308, 0.15384615, 0.07692308,\n",
       "        0.07692308, 0.07692308, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07692308]),\n",
       " array([0.08333333, 0.        , 0.        , 0.        , 0.08333333,\n",
       "        0.08333333, 0.        , 0.        , 0.16666667, 0.        ,\n",
       "        0.        , 0.        , 0.08333333, 0.08333333, 0.08333333,\n",
       "        0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.        ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positivos = positivos/np.sum(positivos)\n",
    "negativos = negativos/np.sum(negativos)\n",
    "positivos,negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.75\n"
     ]
    }
   ],
   "source": [
    "def naiveBayes(frase, positivos,negativos):\n",
    "    prob = 1\n",
    "    for palavra in frase.split(\" \"):\n",
    "        for p in pontuacao:\n",
    "            palavra = palavra.replace(p,'')\n",
    "        if(palavra in palavrasPausa or negativos[vocabulario[palavra]] == 0):\n",
    "            continue\n",
    "        prob *= positivos[vocabulario[palavra]]/negativos[vocabulario[palavra]]\n",
    "    return prob > 1\n",
    "\n",
    "def runNaiveBayes(data):\n",
    "    result = []\n",
    "    positivos, negativos = somarFrequencia(dados)\n",
    "    positivos = positivos/np.sum(positivos)\n",
    "    negativos = negativos/np.sum(negativos)\n",
    "    for frase in data.corpo:\n",
    "        result.append(naiveBayes(frase,positivos,negativos))\n",
    "    return result\n",
    "\n",
    "print(\"Acc\",np.sum(np.array(runNaiveBayes(dados)) == np.array(dados.classes))/len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Smoothing\n",
    "\n",
    "Até então a tivemos o cálculo dos termos da seguinte forma\n",
    "\n",
    "$$P(w_{i}|class) = \\frac{freq(w_{i},class)}{N_{class}}$$\n",
    "\n",
    "Mas obtivemos a problematica de que quando calculamos $\\prod_{i=1}^{m}{\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)}}$, poderiamos ter divisão por zero se uma palavra $w_{i}$ não existisse em uma classe. Contornamos isso dando \"continue\" quando o denominador era zero.\n",
    "\n",
    "No caso, esse método serve justamente para que não seja feito esse contorno. Ele basicamente adiciona 1 no numerador, e para garantir a normalização dos valores e que a soma das probabilidades ainda resulte em 1, ele soma $V$ ao denominador, onde $V$ é o total de palavras únicas do nosso vocabulário. O resultado fica:\n",
    "\n",
    "$$P(w_{i}|class) = \\frac{freq(w_{i},class) + 1}{N_{class} + V}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.0\n"
     ]
    }
   ],
   "source": [
    "def runNaiveBayesNormalized(data):\n",
    "    result = []\n",
    "    positivos, negativos = somarFrequencia(dados)\n",
    "    positivos = (positivos + 1)/(np.sum(positivos) +len(vocabulario))\n",
    "    negativos = (negativos + 1)/(np.sum(negativos) +len(vocabulario))\n",
    "    for frase in data.corpo:\n",
    "        result.append(naiveBayes(frase,positivos,negativos))\n",
    "    return result\n",
    "\n",
    "print(\"Acc\",np.sum(np.array(runNaiveBayesNormalized(dados)) == np.array(dados.classes))/len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "\n",
    "Interessante que a própria precisão aumentou ao aplicar a tecnica de normalização. Em suma, esse estudo foi sobre o algoritmo Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes com Log Likelihood\n",
    "\n",
    "Aprendemos que o método de Naive Bayes se baseia no seguinte produtório:\n",
    "\n",
    "$$\\prod_{i=1}^{m}{\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)}}$$\n",
    "\n",
    "Porém sabemos que trabalhar com produtos e probabilidade não é algo interessante, visto que uma série de produtos flutuantes pode gerar um underflow, perdendo a precisão das casas decimais. Com isso propõe-se o seguinte método. Se para que tenhamos uma classe positiva segue que:\n",
    "\n",
    "$$\\prod_{i=1}^{m}{\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)}} > 1$$\n",
    "\n",
    "Então, se aplicarmos log teremos\n",
    "\n",
    "$$log(\\prod_{i=1}^{m}{\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)}}) > log(1)$$\n",
    "\n",
    "E por tanto:\n",
    "\n",
    "$$\\sum_{i=1}^{m}{log(\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)})} > 0$$\n",
    "\n",
    "com isso evitamos trabalhar com produtório e resolvemos o problema de underflow.\n",
    "\n",
    "\n",
    "#### Mas e se os dados estiverem desbalanceados ? \n",
    "\n",
    "Dados desbalanceados implicam que as palavras neutras estão mal divididas tendendo a estarem em conjuntos positivos ou negativos. Isso, a priore causa um problema no cálculo da naive bayes. Por isso se propõe o log prior.\n",
    "\n",
    "O log prior é um fator que é acrescido na fórmula da log likelihood. Ele é expresso pela fórmula.\n",
    "\n",
    "$$\\frac{P(Pos)}{P(Neg)}$$\n",
    "\n",
    "Com isso, a log likelihood ajustada fica na forma:\n",
    "\n",
    "$$\\frac{P(Pos)}{P(Neg)} \\sum_{i=1}^{m}{log(\\frac{P(w_{i}|Pos)}{P(w_{i}|Neg)})}$$\n",
    "\n",
    "Como o log prior deve ser igual a um (caso os dados estejam balanceados), não afetará o cálculo. Todavia, se for diferente de 1, vai servir de peso para deixar as probabilidades mais justas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 1.0\n"
     ]
    }
   ],
   "source": [
    "def naiveBayesLog(frase, positivos,negativos):\n",
    "    prob = 0\n",
    "    for palavra in frase.split(\" \"):\n",
    "        for p in pontuacao:\n",
    "            palavra = palavra.replace(p,'')\n",
    "        if palavra not in list(vocabulario.keys()):\n",
    "            continue\n",
    "        if(palavra in palavrasPausa or negativos[vocabulario[palavra]] == 0):\n",
    "            continue\n",
    "        logPrior = np.sum(positivos)/np.sum(negativos)\n",
    "        prob += np.log(positivos[vocabulario[palavra]]/negativos[vocabulario[palavra]])\n",
    "    return (logPrior * prob)\n",
    "\n",
    "def runNaiveBayesLogNormalized(data):\n",
    "    result = []\n",
    "    positivos, negativos = somarFrequencia(dados)\n",
    "    positivos = (positivos + 1)/(np.sum(positivos) +len(vocabulario))\n",
    "    negativos = (negativos + 1)/(np.sum(negativos) +len(vocabulario))\n",
    "    for frase in data.corpo:\n",
    "        result.append(naiveBayesLog(frase,positivos,negativos) > 0)\n",
    "    return result\n",
    "\n",
    "print(\"Acc\",np.sum(np.array(runNaiveBayesLogNormalized(dados)) == np.array(dados.classes))/len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicações do método de Naive Bayes\n",
    "\n",
    "Author identification\n",
    "\n",
    "Spam filtering \n",
    "\n",
    "Information retrieval \n",
    "\n",
    "Word disambiguation \n",
    "\n",
    "This method is usually used as a simple baseline. It also really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
