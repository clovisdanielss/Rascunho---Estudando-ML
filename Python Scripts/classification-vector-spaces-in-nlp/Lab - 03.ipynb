{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espaços Vetoriais\n",
    "\n",
    "É um modelo que é útil para fazer distinção do significado das palavras. Isto é, mesmo com palavras iguais em contexto as quais possuem significados distintos ou vice-versa, esse modelo se aplica como uma solução útil para tais situações.\n",
    "\n",
    "Isto indica também, que espaços vetoriais será possível capturar informações de relação entre palavras.\n",
    "Informações como:\n",
    "\n",
    "- Quem\n",
    "- O que\n",
    "- Como\n",
    "- Porque\n",
    "\n",
    "serão destiguíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eu': 0,\n",
       " 'gosto': 1,\n",
       " 'comer': 2,\n",
       " 'biscoito': 3,\n",
       " 'odeio': 4,\n",
       " 'você': 5,\n",
       " 'te': 6,\n",
       " 'amo': 7,\n",
       " 'amor': 8,\n",
       " 'minha': 9,\n",
       " 'vida': 10,\n",
       " 'vá': 11,\n",
       " 'para': 12,\n",
       " 'baixa': 13,\n",
       " 'égua': 14,\n",
       " 'pessoa': 15,\n",
       " 'repugnante': 16,\n",
       " 'desagradável': 17,\n",
       " 'amável': 18}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "corpo = [\n",
    "    \"Eu gosto de comer biscoito\",\n",
    "    \"Eu odeio você\",\n",
    "    \"Eu te amo!!\",\n",
    "    \"Você é o amor da minha vida\",\n",
    "    \"Vá para a baixa da égua\",\n",
    "    \"Você é uma pessoa repugnante\",\n",
    "    \"Você é desagradável\",\n",
    "    \"Você é amável\"\n",
    "]\n",
    "\n",
    "classes = [\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1\n",
    "]\n",
    "\n",
    "vocabulario = {}\n",
    "indices = {}\n",
    "pontuacao = ['!',\",\"]\n",
    "palavrasPausa = [\"a\", \"é\", \"uma\", \"de\", \"o\", \"da\"]\n",
    "def criarVocabulario(corpo):\n",
    "    v = {}\n",
    "    i = {}\n",
    "    index = 0\n",
    "    for frase in corpo:\n",
    "        for palavra in frase.split(\" \"):\n",
    "            for p in pontuacao:\n",
    "                palavra = palavra.replace(p,'').lower()\n",
    "            if palavra not in list(v.keys()) and palavra not in palavrasPausa:\n",
    "                v[palavra] = index\n",
    "                i[index] = palavra\n",
    "                index+=1\n",
    "    return v,i    \n",
    "\n",
    "vocabulario, indices = criarVocabulario(corpo)\n",
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de co-ocorrência\n",
    "\n",
    "Os vetores que representam as palavras do vocabulário podem estar localizados em uma chamada matriz de co-ocorrência. Tal matriz, pode ser composta de duas formas:\n",
    "\n",
    "#### Palavra por palavra\n",
    "\n",
    "Uma matriz de co-ocorrência feita palavra por palavra, procura computar a contagem de palavras vizinhas em um vetor de tamanho N para N sendo o total de palavras no vocabulário. Uma palavra é vizinha de outra se e somente se a distância entre ambas é inferior a K (hiperparâmetro). \n",
    "\n",
    "#### Palavra por documento\n",
    "\n",
    "É possível também contar a quantidade de palavras existentes em uma série de documentos com contextos distintos. Assim sendo, o vetor é representado por um tamanho M, onde M é o total de assuntos (classes) dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrizCoocorrencia = np.zeros((len(list(vocabulario.keys())),(len(list(vocabulario.keys())))))\n",
    "\n",
    "def tokenizar(frase):\n",
    "    tokens = []\n",
    "    for palavra in frase.split(\" \"):\n",
    "        for p in pontuacao:\n",
    "            palavra = palavra.replace(p,'').lower()\n",
    "        if palavra not in palavrasPausa:\n",
    "            tokens.append(palavra)\n",
    "    return tokens\n",
    "\n",
    "def contarFrequencia(fraseTokens,k = 2):\n",
    "    for index in range(len(fraseTokens)):\n",
    "        for auxIndex in range(index + 1,len(fraseTokens)):\n",
    "            if(abs(index - auxIndex) <= k):\n",
    "                matrizCoocorrencia[vocabulario[fraseTokens[index]],vocabulario[fraseTokens[auxIndex]]] += 1\n",
    "                matrizCoocorrencia[vocabulario[fraseTokens[auxIndex]],vocabulario[fraseTokens[index]]] += 1\n",
    "\n",
    "for frase in corpo:\n",
    "    contarFrequencia(tokenizar(frase),k=2)\n",
    "    \n",
    "matrizCoocorrencia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2357022603955159, 1.2363638134501385)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(vec):\n",
    "    return vec/(np.linalg.norm(vec))\n",
    "                \n",
    "def euclid(vac,vec):\n",
    "    return np.linalg.norm(vec - vac)\n",
    "\n",
    "a,b= 0,1\n",
    "\n",
    "np.dot(normalize(matrizCoocorrencia[a]),normalize(matrizCoocorrencia[b])),euclid(normalize(matrizCoocorrencia[a]),normalize(matrizCoocorrencia[b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distância euclidiana, apesar de ajudar a identificar a similaridade entre vetor não é a mais utilizada. A similaridade por cosseno é mais segura pois não se baseia no tamanho do corpo utilizado.\n",
    "\n",
    "A formula do cosseno de theta é dada por:\n",
    "\n",
    "$$ cos \\theta = \\frac{<v,w>}{||v||*||w||}$$\n",
    "\n",
    "Por outro lado, a distancia euclidiana pode ser calulada pela fórmula\n",
    "\n",
    "$$ dist(v,w) = || v - w ||$$\n",
    "\n",
    "Lembrando que $||v|| = \\sqrt{\\sum_{i}^{len(v)}{v[i]^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "Permite representar meus dados em dimenções menores, facilitando a vizualização dos mesmos.\n",
    "\n",
    "Passo a passo:\n",
    "\n",
    "1. Computar a matriz normalizada pela média\n",
    "2. Computar matriz de covariância $\\Sigma$\n",
    "3. Aplicar SVD (single value decomposition) em $\\Sigma$, obtendo $U S V$\n",
    "4. A matriz reduzida é $US[:,:k]$ onde $k$ é a dimensão alvo\n",
    "\n",
    "Isto funciona pois serão usados os $k$ autovetores que tem maiores autovalores. Isto significa que são as partes que mais retêm informação da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19)\n"
     ]
    }
   ],
   "source": [
    "#np.linalg.svd(matrizCoocorrencia)\n",
    "\n",
    "matrizCoovariancia = (matrizCoocorrencia - np.mean(matrizCoocorrencia,axis=0))/np.std(matrizCoocorrencia,axis=0)\n",
    "print(matrizCoovariancia.shape)\n",
    "U,S,V = np.linalg.svd(matrizCoovariancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19, 19), (19,), (19, 19))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução de dimencionalidade (PCA)\n",
    "\n",
    "Ao aplicar decomposição de valor singular na matriz de covariância, obtemos U com os auto-vetores de A e S com os seus autovalores ordenados.\n",
    "\n",
    "O resultado do produto entre ambos irá gerar uma matriz onde as primeiras colunas possuem os valores mais significativos de A, pois afinal serão os produtos dos maiores autovalores pelos autovetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu \t\t [0.19759734 4.5848284 ]\n",
      "gosto \t\t [-0.50651114  1.80637789]\n",
      "comer \t\t [-0.50651114  1.80637789]\n",
      "biscoito \t\t [-0.82526318  1.81977248]\n",
      "odeio \t\t [-0.2817173   0.47342932]\n",
      "você \t\t [ 8.41621035 -1.57122539]\n",
      "te \t\t [-0.29896355  1.18001976]\n",
      "amo \t\t [-0.29896355  1.18001976]\n",
      "amor \t\t [ 0.274423   -0.33684374]\n",
      "minha \t\t [ 0.274423   -0.33684374]\n",
      "vida \t\t [ 1.03686773 -0.83242115]\n",
      "vá \t\t [-1.4983054  -1.75844895]\n",
      "para \t\t [-2.06337387 -3.04735723]\n",
      "baixa \t\t [-2.06337387 -3.04735723]\n",
      "égua \t\t [-1.4983054  -1.75844895]\n",
      "pessoa \t\t [ 0.44672364 -0.19110348]\n",
      "repugnante \t\t [ 0.44672364 -0.19110348]\n",
      "desagradável \t\t [-0.62584014  0.11016391]\n",
      "amável \t\t [-0.62584014  0.11016391]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "chaves = list(vocabulario.keys())\n",
    "for line in (U * S)[:,:2]:\n",
    "    print(chaves[index],\"\\t\\t\",line)\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
